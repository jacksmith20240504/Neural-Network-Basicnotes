import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np

# 定义自编码器模型
class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        # 编码器
        self.encoder = nn.Sequential(
            nn.Linear(28 * 28, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 16)
        )
        # 解码器
        self.decoder = nn.Sequential(
            nn.Linear(16, 32),
            nn.ReLU(),
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 256),
            nn.ReLU(),
            nn.Linear(256, 28 * 28),
            nn.Sigmoid()
        )

    def forward(self, x):
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# 数据预处理
transform = transforms.Compose([transforms.ToTensor()])

# 加载 MNIST 数据集
train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)
train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)

# 初始化模型、损失函数和优化器
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Autoencoder().to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 训练模型
num_epochs = 20
for epoch in range(num_epochs):
    total_loss = 0
    for data in train_loader:
        img, _ = data
        img = img.view(img.size(0), -1).to(device)

        # 前向传播
        output = model(img)
        loss = criterion(output, img)

        # 反向传播和优化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')

# 可视化原始图片与重建图片
def imshow(img):
    img = img.cpu().numpy()
    plt.imshow(np.transpose(img, (1, 2, 0)), cmap='gray')
    plt.axis('off')

# 从训练集中取出一批数据
dataiter = iter(train_loader)
images, _ = next(dataiter)

# 对图片进行压缩和重建
model.eval()
with torch.no_grad():
    images = images.to(device)
    images_flat = images.view(images.size(0), -1)
    reconstructed = model(images_flat).view(images.size())

# 显示原始图片和重建图片
n = 10
plt.figure(figsize=(20, 4))
for i in range(n):
    # 显示原始图片
    ax = plt.subplot(2, n, i + 1)
    imshow(images[i])
    
    # 显示重建图片
    ax = plt.subplot(2, n, i + 1 + n)
    imshow(reconstructed[i])

plt.tight_layout()
plt.show()
